{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-Background': {'precision': 0.871, 'recall': 0.835, 'f1-score': 0.853, 'support': 776.0}, 'I-Other': {'precision': 0.723, 'recall': 0.781, 'f1-score': 0.751, 'support': 274.0}, 'I-Problem': {'precision': 0.878, 'recall': 0.899, 'f1-score': 0.888, 'support': 3889.0}, 'I-Test': {'precision': 0.5710000000000001, 'recall': 0.5750000000000001, 'f1-score': 0.5730000000000001, 'support': 160.0}, 'I-Treatment': {'precision': 0.861, 'recall': 0.874, 'f1-score': 0.867, 'support': 2680.0}, 'O': {'precision': 0.9410000000000001, 'recall': 0.932, 'f1-score': 0.936, 'support': 12477.0}, 'accuracy': {'precision': 0.909, 'recall': 0.909, 'f1-score': 0.909, 'support': 0.909}, 'macro avg': {'precision': 0.808, 'recall': 0.8160000000000001, 'f1-score': 0.811, 'support': 20256.0}, 'weighted avg': {'precision': 0.91, 'recall': 0.909, 'f1-score': 0.909, 'support': 20256.0}, 'macro_wo_O': {'precision': 0.781, 'recall': 0.793, 'f1-score': 0.786, 'support': 7779.0}}\n",
      "{'I-Background': {'precision': 0.837, 'recall': 0.746, 'f1-score': 0.789, 'support': 863.0}, 'I-Other': {'precision': 0.679, 'recall': 0.8130000000000001, 'f1-score': 0.74, 'support': 273.0}, 'I-Problem': {'precision': 0.874, 'recall': 0.912, 'f1-score': 0.892, 'support': 3749.0}, 'I-Test': {'precision': 0.673, 'recall': 0.66, 'f1-score': 0.667, 'support': 209.0}, 'I-Treatment': {'precision': 0.837, 'recall': 0.843, 'f1-score': 0.84, 'support': 2648.0}, 'O': {'precision': 0.934, 'recall': 0.924, 'f1-score': 0.929, 'support': 12813.0}, 'accuracy': {'precision': 0.9, 'recall': 0.9, 'f1-score': 0.9, 'support': 0.9}, 'macro avg': {'precision': 0.806, 'recall': 0.8160000000000001, 'f1-score': 0.81, 'support': 20555.0}, 'weighted avg': {'precision': 0.901, 'recall': 0.9, 'f1-score': 0.9, 'support': 20555.0}, 'macro_wo_O': {'precision': 0.78, 'recall': 0.795, 'f1-score': 0.786, 'support': 7742.0}}\n",
      "{'I-Background': {'precision': 0.842, 'recall': 0.798, 'f1-score': 0.8190000000000001, 'support': 970.0}, 'I-Other': {'precision': 0.677, 'recall': 0.804, 'f1-score': 0.735, 'support': 240.0}, 'I-Problem': {'precision': 0.877, 'recall': 0.897, 'f1-score': 0.887, 'support': 3923.0}, 'I-Test': {'precision': 0.671, 'recall': 0.538, 'f1-score': 0.598, 'support': 182.0}, 'I-Treatment': {'precision': 0.876, 'recall': 0.843, 'f1-score': 0.859, 'support': 2830.0}, 'O': {'precision': 0.932, 'recall': 0.937, 'f1-score': 0.935, 'support': 13106.0}, 'accuracy': {'precision': 0.906, 'recall': 0.906, 'f1-score': 0.906, 'support': 0.906}, 'macro avg': {'precision': 0.8130000000000001, 'recall': 0.803, 'f1-score': 0.805, 'support': 21251.0}, 'weighted avg': {'precision': 0.905, 'recall': 0.906, 'f1-score': 0.905, 'support': 21251.0}, 'macro_wo_O': {'precision': 0.789, 'recall': 0.776, 'f1-score': 0.78, 'support': 8145.0}}\n",
      "{'I-Background': {'precision': 0.8310000000000001, 'recall': 0.811, 'f1-score': 0.8210000000000001, 'support': 806.0}, 'I-Other': {'precision': 0.752, 'recall': 0.772, 'f1-score': 0.762, 'support': 267.0}, 'I-Problem': {'precision': 0.882, 'recall': 0.896, 'f1-score': 0.889, 'support': 3845.0}, 'I-Test': {'precision': 0.654, 'recall': 0.643, 'f1-score': 0.649, 'support': 185.0}, 'I-Treatment': {'precision': 0.8260000000000001, 'recall': 0.877, 'f1-score': 0.851, 'support': 2551.0}, 'O': {'precision': 0.9440000000000001, 'recall': 0.929, 'f1-score': 0.937, 'support': 12950.0}, 'accuracy': {'precision': 0.907, 'recall': 0.907, 'f1-score': 0.907, 'support': 0.907}, 'macro avg': {'precision': 0.8150000000000001, 'recall': 0.8220000000000001, 'f1-score': 0.8180000000000001, 'support': 20604.0}, 'weighted avg': {'precision': 0.908, 'recall': 0.907, 'f1-score': 0.908, 'support': 20604.0}, 'macro_wo_O': {'precision': 0.789, 'recall': 0.8, 'f1-score': 0.794, 'support': 7654.0}}\n",
      "{'I-Background': {'precision': 0.861, 'recall': 0.799, 'f1-score': 0.8290000000000001, 'support': 807.0}, 'I-Other': {'precision': 0.635, 'recall': 0.796, 'f1-score': 0.707, 'support': 221.0}, 'I-Problem': {'precision': 0.892, 'recall': 0.908, 'f1-score': 0.899, 'support': 3861.0}, 'I-Test': {'precision': 0.653, 'recall': 0.5, 'f1-score': 0.5660000000000001, 'support': 196.0}, 'I-Treatment': {'precision': 0.852, 'recall': 0.862, 'f1-score': 0.857, 'support': 2670.0}, 'O': {'precision': 0.9400000000000001, 'recall': 0.936, 'f1-score': 0.9380000000000001, 'support': 12805.0}, 'accuracy': {'precision': 0.91, 'recall': 0.91, 'f1-score': 0.91, 'support': 0.91}, 'macro avg': {'precision': 0.806, 'recall': 0.8, 'f1-score': 0.8, 'support': 20560.0}, 'weighted avg': {'precision': 0.91, 'recall': 0.91, 'f1-score': 0.91, 'support': 20560.0}, 'macro_wo_O': {'precision': 0.779, 'recall': 0.773, 'f1-score': 0.772, 'support': 7755.0}}\n",
      "Binary results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>{'mean': 0.938, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.932, 'std': 0.005}</td>\n",
       "      <td>{'mean': 0.935, 'std': 0.003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>{'mean': 0.889, 'std': 0.008}</td>\n",
       "      <td>{'mean': 0.9, 'std': 0.007}</td>\n",
       "      <td>{'mean': 0.894, 'std': 0.005}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.914, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.916, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.915, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.92, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.919, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.92, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "O             {'mean': 0.938, 'std': 0.004}  {'mean': 0.932, 'std': 0.005}   \n",
       "I             {'mean': 0.889, 'std': 0.008}    {'mean': 0.9, 'std': 0.007}   \n",
       "macro avg     {'mean': 0.914, 'std': 0.004}  {'mean': 0.916, 'std': 0.004}   \n",
       "weighted avg   {'mean': 0.92, 'std': 0.004}  {'mean': 0.919, 'std': 0.004}   \n",
       "\n",
       "                                   f1-score  \n",
       "O             {'mean': 0.935, 'std': 0.003}  \n",
       "I             {'mean': 0.894, 'std': 0.005}  \n",
       "macro avg     {'mean': 0.915, 'std': 0.004}  \n",
       "weighted avg   {'mean': 0.92, 'std': 0.004}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# This is the base directory where your fold reports are located.\n",
    "dataset_name = 'phee'\n",
    "model_name='bioclinicalbert'\n",
    "base_dir = f'analysis/{model_name}/{dataset_name}/reports'  # Replace with your actual path\n",
    "\n",
    "# Initialize dictionaries to hold all the metric values from each fold.\n",
    "binary_metrics = {\n",
    "    'O': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'I': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'macro avg': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'weighted avg': {'precision': [], 'recall': [], 'f1-score': []}\n",
    "}\n",
    "\n",
    "multiclass_metrics = {\n",
    "    \"macro avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"weighted avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"macro_wo_O\": {'precision': [], 'recall': [], 'f1-score': []}\n",
    "\n",
    "}\n",
    "\n",
    "# Process each fold\n",
    "for fold in range(5):\n",
    "    fold_dir = os.path.join(base_dir, f'fold{fold}')\n",
    "\n",
    "    # Load binary classification report\n",
    "    with open(os.path.join(fold_dir, 'binary_classification_report.json'), 'r') as f:\n",
    "        binary_report = json.load(f)\n",
    "        for category in binary_metrics.keys():\n",
    "            for metric in binary_metrics[category].keys():\n",
    "                binary_metrics[category][metric].append(binary_report[category][metric])\n",
    "\n",
    "    # Load multiclass classification report\n",
    "    multi_df = pd.read_json(os.path.join(fold_dir, 'multiclass_classification_report.json'))\n",
    "  \n",
    "    # with open(os.path.join(fold_dir, 'multiclass_classification_report.json'), 'r') as f:\n",
    "    multiclass_report = multi_df.T.to_dict()\n",
    "    print(multiclass_report)\n",
    "\n",
    "    for category in multiclass_metrics.keys():\n",
    "\n",
    "        for metric in multiclass_metrics[category].keys():\n",
    "            multiclass_metrics[category][metric].append(multiclass_report[category][metric])\n",
    "\n",
    "# Calculate mean and standard deviation for binary metrics\n",
    "binary_results = {}\n",
    "for category, metrics in binary_metrics.items():\n",
    " \n",
    "    binary_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        binary_results[category][metric] = {\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Do the same for multiclass metrics\n",
    "multiclass_results = {}\n",
    "for category, metrics in multiclass_metrics.items():\n",
    "    multiclass_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        multiclass_results[category][metric] = {\n",
    "            # round to 3 decimal places\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Now you have binary_results and multiclass_results with the mean and std dev of each metric.\n",
    "print('Binary results:')\n",
    "# dict to dataframe\n",
    "binary_results = pd.DataFrame(binary_results)    \n",
    "binary_results.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.81, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.811, 'std': 0.008}</td>\n",
       "      <td>{'mean': 0.809, 'std': 0.006}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.907, 'std': 0.003}</td>\n",
       "      <td>{'mean': 0.906, 'std': 0.003}</td>\n",
       "      <td>{'mean': 0.906, 'std': 0.004}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_wo_O</th>\n",
       "      <td>{'mean': 0.784, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.787, 'std': 0.011}</td>\n",
       "      <td>{'mean': 0.784, 'std': 0.007}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "macro avg      {'mean': 0.81, 'std': 0.004}  {'mean': 0.811, 'std': 0.008}   \n",
       "weighted avg  {'mean': 0.907, 'std': 0.003}  {'mean': 0.906, 'std': 0.003}   \n",
       "macro_wo_O    {'mean': 0.784, 'std': 0.004}  {'mean': 0.787, 'std': 0.011}   \n",
       "\n",
       "                                   f1-score  \n",
       "macro avg     {'mean': 0.809, 'std': 0.006}  \n",
       "weighted avg  {'mean': 0.906, 'std': 0.004}  \n",
       "macro_wo_O    {'mean': 0.784, 'std': 0.007}  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Multiclass results:')\n",
    "# dict to dataframe\n",
    "multiclass_results = pd.DataFrame(multiclass_results)\n",
    "multiclass_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: analysis/scibert-mt/mtsamples/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/scibert-mt/mtsamples2/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/scibert-mt/doc-patient/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bluebert-mt/mtsamples/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bluebert-mt/mtsamples2/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bluebert-mt/doc-patient/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bert-mt/mtsamples/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bert-mt/mtsamples2/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bert-mt/doc-patient/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/mtsamples/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/mtsamples2/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/doc-patient/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/mtsamples/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/mtsamples2/reports/fold0/multiclass_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/doc-patient/reports/fold0/multiclass_classification_report.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scibert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bluebert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertclinical-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.786</td>\n",
       "      <td>0.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bioclinicalbert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model           Dataset  Macro Precision  Macro Recall  \\\n",
       "0          scibert-mt  cross-validation            0.814         0.762   \n",
       "1         bluebert-mt  cross-validation            0.799         0.732   \n",
       "2             bert-mt  cross-validation            0.766         0.691   \n",
       "3     bertclinical-mt  cross-validation            0.798         0.786   \n",
       "4  bioclinicalbert-mt  cross-validation            0.791         0.758   \n",
       "\n",
       "   Macro F1-Score  \n",
       "0           0.782  \n",
       "1           0.762  \n",
       "2           0.719  \n",
       "3           0.787  \n",
       "4           0.771  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model names and dataset names\n",
    "model_names = ['scibert-mt', 'bluebert-mt', 'bert-mt', 'bertclinical-mt', 'bioclinicalbert-mt']\n",
    "dataset_names = ['mtsamples', 'mtsamples2', 'doc-patient', 'cross-validation']\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and dataset to read the respective JSON files\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        file_path = f'analysis/{model_name}/{dataset_name}/reports/fold0/multiclass_classification_report.json'\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    report = json.load(file)\n",
    "                    # Extract the macro average values for precision, recall, and f1-score\n",
    "                    macro_avg = {\n",
    "                        'Model': model_name,\n",
    "                        'Dataset': dataset_name,\n",
    "                        'Macro Precision': report['precision']['macro_wo_O'],\n",
    "                        'Macro Recall': report['recall']['macro_wo_O'],\n",
    "                        'Macro F1-Score': report['f1-score']['macro_wo_O']\n",
    "                    }\n",
    "                    results.append(macro_avg)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON from file: {file_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File not found: analysis/scibert-mt/mtsamples/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/scibert-mt/mtsamples2/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/scibert-mt/doc-patient/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bluebert-mt/mtsamples/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bluebert-mt/mtsamples2/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bluebert-mt/doc-patient/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bert-mt/mtsamples/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bert-mt/mtsamples2/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bert-mt/doc-patient/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/mtsamples/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/mtsamples2/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bertclinical-mt/doc-patient/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/mtsamples/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/mtsamples2/reports/fold0/binary_classification_report.json\n",
      "File not found: analysis/bioclinicalbert-mt/doc-patient/reports/fold0/binary_classification_report.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scibert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.917757</td>\n",
       "      <td>0.914834</td>\n",
       "      <td>0.916176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bluebert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.910461</td>\n",
       "      <td>0.905167</td>\n",
       "      <td>0.907449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.914517</td>\n",
       "      <td>0.909594</td>\n",
       "      <td>0.911740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertclinical-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.909428</td>\n",
       "      <td>0.907194</td>\n",
       "      <td>0.908237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bioclinicalbert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.911766</td>\n",
       "      <td>0.911766</td>\n",
       "      <td>0.911766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model           Dataset  Macro Precision  Macro Recall  \\\n",
       "0          scibert-mt  cross-validation         0.917757      0.914834   \n",
       "1         bluebert-mt  cross-validation         0.910461      0.905167   \n",
       "2             bert-mt  cross-validation         0.914517      0.909594   \n",
       "3     bertclinical-mt  cross-validation         0.909428      0.907194   \n",
       "4  bioclinicalbert-mt  cross-validation         0.911766      0.911766   \n",
       "\n",
       "   Macro F1-Score  \n",
       "0        0.916176  \n",
       "1        0.907449  \n",
       "2        0.911740  \n",
       "3        0.908237  \n",
       "4        0.911766  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define the model names and dataset names\n",
    "model_names = ['scibert-mt', 'bluebert-mt', 'bert-mt', 'bertclinical-mt', 'bioclinicalbert-mt']\n",
    "dataset_names = ['mtsamples', 'mtsamples2', 'doc-patient', 'cross-validation']\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and dataset to read the respective JSON files\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        file_path = f'analysis/{model_name}/{dataset_name}/reports/fold0/binary_classification_report.json'\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r') as file:\n",
    "                try:\n",
    "                    report = json.load(file)\n",
    "                    # Extract the macro average values for precision, recall, and f1-score\n",
    "                    macro_avg = {\n",
    "                        'Model': model_name,\n",
    "                        'Dataset': dataset_name,\n",
    "                        'Macro Precision': report['macro avg']['precision'],\n",
    "                        'Macro Recall': report['macro avg']['recall'],\n",
    "                        'Macro F1-Score': report['macro avg']['f1-score']\n",
    "                    }\n",
    "                    results.append(macro_avg)\n",
    "                except json.JSONDecodeError:\n",
    "                    print(f\"Error decoding JSON from file: {file_path}\")\n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results DataFrame\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table with mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the model names and dataset names\n",
    "model_names = ['scibert-mt', 'bluebert-mt', 'bert-mt', 'bertclinical-mt', 'bioclinicalbert-mt']\n",
    "dataset_names = ['cross-validation']\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Iterate over each model and dataset to read the respective JSON files\n",
    "for model_name in model_names:\n",
    "    for dataset_name in dataset_names:\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        f1_scores = []\n",
    "        for fold in range(10):\n",
    "            file_path = f'analysis/{model_name}/{dataset_name}/reports/fold{fold}/multiclass_classification_report.json'\n",
    "            if os.path.exists(file_path):\n",
    "                with open(file_path, 'r') as file:\n",
    "                    try:\n",
    "                        report = json.load(file)\n",
    "                        precisions.append(report['precision']['macro_wo_O'])\n",
    "                        recalls.append(report['recall']['macro_wo_O'])\n",
    "                        f1_scores.append(report['f1-score']['macro_wo_O'])\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Error decoding JSON from file: {file_path}\")\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "        \n",
    "        if precisions and recalls and f1_scores:\n",
    "            # Calculate mean and std for each metric\n",
    "            precision_mean = np.mean(precisions)\n",
    "            precision_std = np.std(precisions)\n",
    "            recall_mean = np.mean(recalls)\n",
    "            recall_std = np.std(recalls)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            \n",
    "            # Store the results in the list\n",
    "            results.append({\n",
    "                'Model': model_name,\n",
    "                'Dataset': dataset_name,\n",
    "                'Macro Precision': f\"{precision_mean:.4f} ± {precision_std:.4f}\",\n",
    "                'Macro Recall': f\"{recall_mean:.4f} ± {recall_std:.4f}\",\n",
    "                'Macro F1-Score': f\"{f1_mean:.4f} ± {f1_std:.4f}\"\n",
    "            })\n",
    "\n",
    "# Convert the results list to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Macro Precision</th>\n",
       "      <th>Macro Recall</th>\n",
       "      <th>Macro F1-Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>scibert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.7769 ± 0.0398</td>\n",
       "      <td>0.7570 ± 0.0355</td>\n",
       "      <td>0.7590 ± 0.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bluebert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.7680 ± 0.0373</td>\n",
       "      <td>0.7353 ± 0.0354</td>\n",
       "      <td>0.7424 ± 0.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.7357 ± 0.0288</td>\n",
       "      <td>0.7006 ± 0.0433</td>\n",
       "      <td>0.7100 ± 0.0302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bertclinical-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.7813 ± 0.0337</td>\n",
       "      <td>0.7588 ± 0.0350</td>\n",
       "      <td>0.7617 ± 0.0278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bioclinicalbert-mt</td>\n",
       "      <td>cross-validation</td>\n",
       "      <td>0.7911 ± 0.0222</td>\n",
       "      <td>0.7381 ± 0.0331</td>\n",
       "      <td>0.7569 ± 0.0170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model           Dataset  Macro Precision     Macro Recall  \\\n",
       "0          scibert-mt  cross-validation  0.7769 ± 0.0398  0.7570 ± 0.0355   \n",
       "1         bluebert-mt  cross-validation  0.7680 ± 0.0373  0.7353 ± 0.0354   \n",
       "2             bert-mt  cross-validation  0.7357 ± 0.0288  0.7006 ± 0.0433   \n",
       "3     bertclinical-mt  cross-validation  0.7813 ± 0.0337  0.7588 ± 0.0350   \n",
       "4  bioclinicalbert-mt  cross-validation  0.7911 ± 0.0222  0.7381 ± 0.0331   \n",
       "\n",
       "    Macro F1-Score  \n",
       "0  0.7590 ± 0.0224  \n",
       "1  0.7424 ± 0.0222  \n",
       "2  0.7100 ± 0.0302  \n",
       "3  0.7617 ± 0.0278  \n",
       "4  0.7569 ± 0.0170  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
