{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'I-Background': {'precision': 0.833, 'recall': 0.895, 'f1-score': 0.863, 'support': 95.0}, 'I-Other': {'precision': 0.969, 'recall': 0.5740000000000001, 'f1-score': 0.721, 'support': 54.0}, 'I-Problem': {'precision': 0.911, 'recall': 0.862, 'f1-score': 0.886, 'support': 629.0}, 'I-Test': {'precision': 0.792, 'recall': 0.623, 'f1-score': 0.6970000000000001, 'support': 61.0}, 'I-Treatment': {'precision': 0.755, 'recall': 0.552, 'f1-score': 0.638, 'support': 67.0}, 'O': {'precision': 0.91, 'recall': 0.961, 'f1-score': 0.935, 'support': 1450.0}, 'accuracy': {'precision': 0.902, 'recall': 0.902, 'f1-score': 0.902, 'support': 0.902}, 'macro avg': {'precision': 0.862, 'recall': 0.744, 'f1-score': 0.79, 'support': 2356.0}, 'weighted avg': {'precision': 0.901, 'recall': 0.902, 'f1-score': 0.899, 'support': 2356.0}, 'macro_wo_O': {'precision': 0.852, 'recall': 0.7010000000000001, 'f1-score': 0.761, 'support': 906.0}}\n",
      "{'I-Background': {'precision': 0.857, 'recall': 0.8210000000000001, 'f1-score': 0.839, 'support': 95.0}, 'I-Other': {'precision': 1.0, 'recall': 0.611, 'f1-score': 0.759, 'support': 54.0}, 'I-Problem': {'precision': 0.914, 'recall': 0.881, 'f1-score': 0.897, 'support': 629.0}, 'I-Test': {'precision': 0.717, 'recall': 0.623, 'f1-score': 0.667, 'support': 61.0}, 'I-Treatment': {'precision': 0.673, 'recall': 0.552, 'f1-score': 0.607, 'support': 67.0}, 'O': {'precision': 0.922, 'recall': 0.965, 'f1-score': 0.9430000000000001, 'support': 1450.0}, 'accuracy': {'precision': 0.908, 'recall': 0.908, 'f1-score': 0.908, 'support': 0.908}, 'macro avg': {'precision': 0.847, 'recall': 0.742, 'f1-score': 0.785, 'support': 2356.0}, 'weighted avg': {'precision': 0.906, 'recall': 0.908, 'f1-score': 0.905, 'support': 2356.0}, 'macro_wo_O': {'precision': 0.8320000000000001, 'recall': 0.6980000000000001, 'f1-score': 0.754, 'support': 906.0}}\n",
      "{'I-Background': {'precision': 0.872, 'recall': 0.863, 'f1-score': 0.868, 'support': 95.0}, 'I-Other': {'precision': 0.971, 'recall': 0.63, 'f1-score': 0.764, 'support': 54.0}, 'I-Problem': {'precision': 0.901, 'recall': 0.886, 'f1-score': 0.893, 'support': 629.0}, 'I-Test': {'precision': 0.735, 'recall': 0.59, 'f1-score': 0.655, 'support': 61.0}, 'I-Treatment': {'precision': 0.6940000000000001, 'recall': 0.507, 'f1-score': 0.586, 'support': 67.0}, 'O': {'precision': 0.923, 'recall': 0.961, 'f1-score': 0.9420000000000001, 'support': 1450.0}, 'accuracy': {'precision': 0.907, 'recall': 0.907, 'f1-score': 0.907, 'support': 0.907}, 'macro avg': {'precision': 0.849, 'recall': 0.74, 'f1-score': 0.785, 'support': 2356.0}, 'weighted avg': {'precision': 0.905, 'recall': 0.907, 'f1-score': 0.904, 'support': 2356.0}, 'macro_wo_O': {'precision': 0.835, 'recall': 0.6950000000000001, 'f1-score': 0.753, 'support': 906.0}}\n",
      "{'I-Background': {'precision': 0.848, 'recall': 0.8210000000000001, 'f1-score': 0.834, 'support': 95.0}, 'I-Other': {'precision': 1.0, 'recall': 0.556, 'f1-score': 0.714, 'support': 54.0}, 'I-Problem': {'precision': 0.914, 'recall': 0.881, 'f1-score': 0.897, 'support': 629.0}, 'I-Test': {'precision': 0.745, 'recall': 0.672, 'f1-score': 0.707, 'support': 61.0}, 'I-Treatment': {'precision': 0.619, 'recall': 0.582, 'f1-score': 0.6000000000000001, 'support': 67.0}, 'O': {'precision': 0.926, 'recall': 0.965, 'f1-score': 0.9450000000000001, 'support': 1450.0}, 'accuracy': {'precision': 0.909, 'recall': 0.909, 'f1-score': 0.909, 'support': 0.909}, 'macro avg': {'precision': 0.842, 'recall': 0.746, 'f1-score': 0.783, 'support': 2356.0}, 'weighted avg': {'precision': 0.908, 'recall': 0.909, 'f1-score': 0.907, 'support': 2356.0}, 'macro_wo_O': {'precision': 0.8250000000000001, 'recall': 0.7020000000000001, 'f1-score': 0.751, 'support': 906.0}}\n",
      "{'I-Background': {'precision': 0.837, 'recall': 0.811, 'f1-score': 0.8240000000000001, 'support': 95.0}, 'I-Other': {'precision': 0.93, 'recall': 0.741, 'f1-score': 0.8250000000000001, 'support': 54.0}, 'I-Problem': {'precision': 0.906, 'recall': 0.878, 'f1-score': 0.892, 'support': 629.0}, 'I-Test': {'precision': 0.732, 'recall': 0.672, 'f1-score': 0.7010000000000001, 'support': 61.0}, 'I-Treatment': {'precision': 0.623, 'recall': 0.5670000000000001, 'f1-score': 0.594, 'support': 67.0}, 'O': {'precision': 0.927, 'recall': 0.9560000000000001, 'f1-score': 0.9410000000000001, 'support': 1450.0}, 'accuracy': {'precision': 0.906, 'recall': 0.906, 'f1-score': 0.906, 'support': 0.906}, 'macro avg': {'precision': 0.8260000000000001, 'recall': 0.771, 'f1-score': 0.796, 'support': 2356.0}, 'weighted avg': {'precision': 0.904, 'recall': 0.906, 'f1-score': 0.905, 'support': 2356.0}, 'macro_wo_O': {'precision': 0.806, 'recall': 0.734, 'f1-score': 0.767, 'support': 906.0}}\n",
      "Binary results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>O</th>\n",
       "      <td>{'mean': 0.922, 'std': 0.006}</td>\n",
       "      <td>{'mean': 0.962, 'std': 0.003}</td>\n",
       "      <td>{'mean': 0.941, 'std': 0.003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>{'mean': 0.934, 'std': 0.005}</td>\n",
       "      <td>{'mean': 0.869, 'std': 0.011}</td>\n",
       "      <td>{'mean': 0.9, 'std': 0.007}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.928, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.915, 'std': 0.006}</td>\n",
       "      <td>{'mean': 0.921, 'std': 0.005}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.926, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.926, 'std': 0.004}</td>\n",
       "      <td>{'mean': 0.925, 'std': 0.005}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "O             {'mean': 0.922, 'std': 0.006}  {'mean': 0.962, 'std': 0.003}   \n",
       "I             {'mean': 0.934, 'std': 0.005}  {'mean': 0.869, 'std': 0.011}   \n",
       "macro avg     {'mean': 0.928, 'std': 0.004}  {'mean': 0.915, 'std': 0.006}   \n",
       "weighted avg  {'mean': 0.926, 'std': 0.004}  {'mean': 0.926, 'std': 0.004}   \n",
       "\n",
       "                                   f1-score  \n",
       "O             {'mean': 0.941, 'std': 0.003}  \n",
       "I               {'mean': 0.9, 'std': 0.007}  \n",
       "macro avg     {'mean': 0.921, 'std': 0.005}  \n",
       "weighted avg  {'mean': 0.925, 'std': 0.005}  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# This is the base directory where your fold reports are located.\n",
    "dataset_name = 'mtsamples'\n",
    "base_dir = f'analysis/{dataset_name}/reports'  # Replace with your actual path\n",
    "\n",
    "# Initialize dictionaries to hold all the metric values from each fold.\n",
    "binary_metrics = {\n",
    "    'O': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'I': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'macro avg': {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    'weighted avg': {'precision': [], 'recall': [], 'f1-score': []}\n",
    "}\n",
    "\n",
    "multiclass_metrics = {\n",
    "    \"macro avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"weighted avg\": {'precision': [], 'recall': [], 'f1-score': []},\n",
    "    \"macro_wo_O\": {'precision': [], 'recall': [], 'f1-score': []}\n",
    "\n",
    "}\n",
    "\n",
    "# Process each fold\n",
    "for fold in range(5):\n",
    "    fold_dir = os.path.join(base_dir, f'fold{fold}')\n",
    "\n",
    "    # Load binary classification report\n",
    "    with open(os.path.join(fold_dir, 'binary_classification_report.json'), 'r') as f:\n",
    "        binary_report = json.load(f)\n",
    "        for category in binary_metrics.keys():\n",
    "            for metric in binary_metrics[category].keys():\n",
    "                binary_metrics[category][metric].append(binary_report[category][metric])\n",
    "\n",
    "    # Load multiclass classification report\n",
    "    multi_df = pd.read_json(os.path.join(fold_dir, 'multiclass_classification_report.json'))\n",
    "  \n",
    "    # with open(os.path.join(fold_dir, 'multiclass_classification_report.json'), 'r') as f:\n",
    "    multiclass_report = multi_df.T.to_dict()\n",
    "    print(multiclass_report)\n",
    "\n",
    "    for category in multiclass_metrics.keys():\n",
    "\n",
    "        for metric in multiclass_metrics[category].keys():\n",
    "            multiclass_metrics[category][metric].append(multiclass_report[category][metric])\n",
    "\n",
    "# Calculate mean and standard deviation for binary metrics\n",
    "binary_results = {}\n",
    "for category, metrics in binary_metrics.items():\n",
    " \n",
    "    binary_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        binary_results[category][metric] = {\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Do the same for multiclass metrics\n",
    "multiclass_results = {}\n",
    "for category, metrics in multiclass_metrics.items():\n",
    "    multiclass_results[category] = {}\n",
    "    for metric, values in metrics.items():\n",
    "        multiclass_results[category][metric] = {\n",
    "            # round to 3 decimal places\n",
    "            'mean': round(np.mean(values), 3),\n",
    "            'std': round(np.std(values), 3)\n",
    "        }\n",
    "\n",
    "# Now you have binary_results and multiclass_results with the mean and std dev of each metric.\n",
    "print('Binary results:')\n",
    "# dict to dataframe\n",
    "binary_results = pd.DataFrame(binary_results)    \n",
    "binary_results.T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>{'mean': 0.845, 'std': 0.012}</td>\n",
       "      <td>{'mean': 0.749, 'std': 0.011}</td>\n",
       "      <td>{'mean': 0.788, 'std': 0.005}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>{'mean': 0.905, 'std': 0.002}</td>\n",
       "      <td>{'mean': 0.906, 'std': 0.002}</td>\n",
       "      <td>{'mean': 0.904, 'std': 0.003}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro_wo_O</th>\n",
       "      <td>{'mean': 0.83, 'std': 0.015}</td>\n",
       "      <td>{'mean': 0.706, 'std': 0.014}</td>\n",
       "      <td>{'mean': 0.757, 'std': 0.006}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  precision                         recall  \\\n",
       "macro avg     {'mean': 0.845, 'std': 0.012}  {'mean': 0.749, 'std': 0.011}   \n",
       "weighted avg  {'mean': 0.905, 'std': 0.002}  {'mean': 0.906, 'std': 0.002}   \n",
       "macro_wo_O     {'mean': 0.83, 'std': 0.015}  {'mean': 0.706, 'std': 0.014}   \n",
       "\n",
       "                                   f1-score  \n",
       "macro avg     {'mean': 0.788, 'std': 0.005}  \n",
       "weighted avg  {'mean': 0.904, 'std': 0.003}  \n",
       "macro_wo_O    {'mean': 0.757, 'std': 0.006}  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Multiclass results:')\n",
    "# dict to dataframe\n",
    "multiclass_results = pd.DataFrame(multiclass_results)\n",
    "multiclass_results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
