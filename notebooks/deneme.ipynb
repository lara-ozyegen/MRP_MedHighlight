{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import BertModel\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import BertModel, BertConfig\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,EarlyStoppingCallback, AutoModelForTokenClassification\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "# from torchcrf import CRF\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import ast\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('/home/ozan/lara/Med-Highlight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O': 0, 'I-Treatment': 1, 'I-Test': 2, 'I-Problem': 3, 'I-Background': 4, 'I-Other': 5}\n",
    "id2label = {0: 'O', 1: 'I-Treatment', 2: 'I-Test', 3: 'I-Problem', 4: 'I-Background', 5: 'I-Other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(example_batch):\n",
    "    example_batch['sentence'] = ast.literal_eval(example_batch['sentence'])\n",
    "    example_batch['tag'] = ast.literal_eval(example_batch['tag'])\n",
    "    example_batch['tag'] = [label2id[label] for label in example_batch['tag']]\n",
    "    return example_batch\n",
    "\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels\n",
    "\n",
    "def tokenize_and_align_labels(examples, tokenizer):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "    \n",
    "    all_labels = examples[\"tag\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def tokenize_and_align_labels_wrapper(examples, tokenizer):\n",
    "    return tokenize_and_align_labels(examples, tokenizer)\n",
    "\n",
    "def untokenize_labels_predictions(word_ids, true_labels, predictions):\n",
    "    untokenized_true_labels = []\n",
    "    untokenized_predictions = []\n",
    "\n",
    "    for sublist_word_ids, sublist_true_labels, sublist_predictions in zip(word_ids, true_labels, predictions):\n",
    "        current_labels = []\n",
    "        current_predictions = []\n",
    "        last_word_id = None\n",
    "\n",
    "        for word_id, label, prediction in zip(sublist_word_ids[1:-1], sublist_true_labels, sublist_predictions):\n",
    "            # Skip if this word_id is the same as the last one (it's a subword)\n",
    "            if word_id == last_word_id:\n",
    "                continue\n",
    "\n",
    "            current_labels.append(label)\n",
    "            current_predictions.append(prediction)\n",
    "            last_word_id = word_id\n",
    "\n",
    "        untokenized_true_labels.append(current_labels)\n",
    "        untokenized_predictions.append(current_predictions)\n",
    "\n",
    "    return untokenized_true_labels, untokenized_predictions\n",
    "\n",
    "class TrainingMonitor:\n",
    "    def __init__(self):\n",
    "        self.best_confusion_matrix = None\n",
    "\n",
    "    def compute_metrics_factory(self, word_ids, fold_no, dataset_name, model_name):\n",
    "        # Define the actual compute_metrics function\n",
    "        def compute_metrics(eval_preds):\n",
    "            logits, labels = eval_preds\n",
    "            print(logits)\n",
    "            print(logits.shape)\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "            # Remove ignored index (special tokens) and convert to labels\n",
    "            true_labels = [[id2label[l] for l in label if l != -100] for label in labels]\n",
    "            true_predictions = [\n",
    "                [id2label[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "                for prediction, label in zip(predictions, labels)\n",
    "            ]\n",
    "\n",
    "            untokenized_true_labels, untokenized_predictions = untokenize_labels_predictions(word_ids, true_labels, true_predictions)\n",
    "\n",
    "            unflat_true = [label for seq in untokenized_true_labels for label in seq]\n",
    "            unflat_pred = [label for seq in untokenized_predictions for label in seq]\n",
    "            unreport = classification_report(y_pred=unflat_pred, y_true=unflat_true, output_dict=True)\n",
    "            unreport['macro_wo_O'] = {'precision': (unreport['I-Background']['precision'] + unreport['I-Other']['precision'] + unreport['I-Problem']['precision'] + unreport['I-Test']['precision'] + unreport['I-Treatment']['precision']) / 5,\n",
    "            'recall': (unreport['I-Background']['recall'] + unreport['I-Other']['recall'] + unreport['I-Problem']['recall'] + unreport['I-Test']['recall'] + unreport['I-Treatment']['recall']) / 5,\n",
    "            'f1-score': (unreport['I-Background']['f1-score'] + unreport['I-Other']['f1-score'] + unreport['I-Problem']['f1-score'] + unreport['I-Test']['f1-score'] + unreport['I-Treatment']['f1-score']) / 5,\n",
    "            'support': (unreport['I-Background']['support'] + unreport['I-Other']['support'] + unreport['I-Problem']['support'] + unreport['I-Test']['support'] + unreport['I-Treatment']['support'])}\n",
    "            \n",
    "            un_report_df = pd.DataFrame(unreport).round(3).T\n",
    "    \n",
    "            cm = confusion_matrix(y_pred=unflat_pred, y_true=unflat_true)\n",
    "            disp = ConfusionMatrixDisplay(cm, display_labels=np.array(['I-Background','I-Other', 'I-Problem', 'I-Test', 'I-Treatment', 'O']))\n",
    "            fig, ax = plt.subplots(figsize=(8, 8))\n",
    "            disp.plot(ax=ax)\n",
    "\n",
    "            \n",
    "            binary_predictions = ['0' if label == 'O' else '1' for label in unflat_pred]\n",
    "            binary_labels = ['0' if label == 'O' else '1' for label in unflat_true]\n",
    "\n",
    "            # Generate a classification report\n",
    "            binary_classification_report = classification_report(y_true=binary_labels, y_pred=binary_predictions, target_names=['O', 'I'], digits=3, output_dict=True)\n",
    "            \n",
    "            # Save the figure to an image file\n",
    "            plt.savefig(f'analysis/{model_name}/{dataset_name}/graphs/fold{fold_no}/confusion_matrix.png')\n",
    "            plt.close()\n",
    "            \n",
    "            with open(f\"analysis/{model_name}/{dataset_name}/reports/fold{fold_no}/multiclass_classification_report.json\", \"w\") as f:\n",
    "                json.dump(un_report_df.to_dict(), f, indent=4)\n",
    "            with open(f\"analysis/{model_name}/{dataset_name}/reports/fold{fold_no}/binary_classification_report.json\", \"w\") as f:\n",
    "                json.dump(binary_classification_report, f, indent=4)\n",
    "                \n",
    "\n",
    "            return {\n",
    "                \"precision\": unreport['macro_wo_O']['precision'],\n",
    "                \"recall\": unreport['macro_wo_O']['recall'],\n",
    "                \"f1\": unreport['macro_wo_O']['f1-score'],\n",
    "                \"accuracy\": unreport['accuracy'],\n",
    "            }\n",
    "        return compute_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForTokenClassification.\nModel type should be one of AlbertConfig, BertConfig, BigBirdConfig, BioGptConfig, BloomConfig, BrosConfig, CamembertConfig, CanineConfig, ConvBertConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, IBertConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LiltConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, NezhaConfig, NystromformerConfig, QDQBertConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 28\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence \u001b[38;5;129;01min\u001b[39;00m test_sentences:\n\u001b[1;32m     24\u001b[0m     test_word_ids\u001b[38;5;241m.\u001b[39mappend(tokenizer(sentence, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, is_split_into_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mword_ids())\n\u001b[0;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForTokenClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrazent/SciFive-base-Pubmed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Training arguments\u001b[39;00m\n\u001b[1;32m     32\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m     33\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./models/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     45\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/lara-medh/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:568\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    564\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[1;32m    566\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    567\u001b[0m     )\n\u001b[0;32m--> 568\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    571\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized configuration class <class 'transformers.models.t5.configuration_t5.T5Config'> for this kind of AutoModel: AutoModelForTokenClassification.\nModel type should be one of AlbertConfig, BertConfig, BigBirdConfig, BioGptConfig, BloomConfig, BrosConfig, CamembertConfig, CanineConfig, ConvBertConfig, Data2VecTextConfig, DebertaConfig, DebertaV2Config, DistilBertConfig, ElectraConfig, ErnieConfig, ErnieMConfig, EsmConfig, FalconConfig, FlaubertConfig, FNetConfig, FunnelConfig, GPT2Config, GPT2Config, GPTBigCodeConfig, GPTNeoConfig, GPTNeoXConfig, IBertConfig, LayoutLMConfig, LayoutLMv2Config, LayoutLMv3Config, LiltConfig, LongformerConfig, LukeConfig, MarkupLMConfig, MegaConfig, MegatronBertConfig, MobileBertConfig, MPNetConfig, MptConfig, MraConfig, NezhaConfig, NystromformerConfig, QDQBertConfig, RemBertConfig, RobertaConfig, RobertaPreLayerNormConfig, RoCBertConfig, RoFormerConfig, SqueezeBertConfig, XLMConfig, XLMRobertaConfig, XLMRobertaXLConfig, XLNetConfig, XmodConfig, YosoConfig."
     ]
    }
   ],
   "source": [
    "dataset_name = 'phee'\n",
    "model_name = 'sci5'\n",
    "for i in range(1):\n",
    "    data = load_dataset('csv', data_files={'train': f'data/processed/{dataset_name}/fold{i}/train.csv'})\n",
    "    \n",
    "    dataset = data['train'].train_test_split(test_size=0.15, seed=42) # 85% training, 15% validation\n",
    "\n",
    "    for file_type in ['train', 'test']:\n",
    "        dataset[file_type] = dataset[file_type].shuffle(seed=42).select(range(int(0.1 * len(dataset[file_type]))))  # Select 10%\n",
    "        dataset[file_type] = dataset[file_type].map(transform)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"razent/SciFive-base-Pubmed\") \n",
    "    data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "\n",
    "    tokenized_datasets = dataset.map(\n",
    "    lambda examples: tokenize_and_align_labels_wrapper(examples, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=dataset['train'].column_names)\n",
    "\n",
    "    # word ids of the tokenized test set to find the original words\n",
    "    test_sentences = dataset['test']['sentence']\n",
    "    test_word_ids = []\n",
    "    for sentence in test_sentences:\n",
    "        test_word_ids.append(tokenizer(sentence, truncation=True, is_split_into_words=True).word_ids())\n",
    "\n",
    "    \n",
    " \n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"razent/SciFive-base-Pubmed\")\n",
    "\n",
    "\n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./models/{model_name}',\n",
    "        num_train_epochs=50,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        logging_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        overwrite_output_dir=True,\n",
    "        learning_rate=3e-5,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        load_best_model_at_end=True,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=5, early_stopping_threshold=0.01)\n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['test'],\n",
    "        data_collator=data_collator,\n",
    "        tokenizer=tokenizer,\n",
    "        compute_metrics=TrainingMonitor().compute_metrics_factory(test_word_ids, fold_no=i, dataset_name=dataset_name, model_name=model_name),\n",
    "        callbacks=[early_stopping_callback]\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "    eval_result = trainer.evaluate()\n",
    "    metric  = eval_result[\"eval_f1\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the whole train data for training with best hyperparameters\n",
    "# evaluate on test set\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
